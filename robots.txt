# Enhanced robots.txt for SEO and indexing
# Allow all major search engines full access to main content and assets

User-agent: *
Allow: /

# Sitemap location
Sitemap: https://nepiskopos.github.io/sitemap.xml

# Explicitly allow all major search engines
User-agent: Googlebot
Allow: /

User-agent: Bingbot
Allow: /

User-agent: Slurp
Allow: /

User-agent: DuckDuckBot
Allow: /

User-agent: Baiduspider
Allow: /

User-agent: YandexBot
Allow: /

# Allow access to important resources
Allow: /index.html
Allow: /sitemap.xml
Allow: /robots.txt
Allow: /humans.txt
Allow: /security.txt
Allow: /.well-known/
Allow: /manifest.json
Allow: /assets/
Allow: /404.html

# Crawl rate optimization
Crawl-delay: 0

# Note: Fragment URLs (#section) are handled client-side
# The sitemap.xml includes all important sections